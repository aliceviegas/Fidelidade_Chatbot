{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00937ea0",
   "metadata": {},
   "source": [
    "# **BUSINESS CASE 4: CHATBOT FIDELIDADE**  \n",
    "\n",
    "\n",
    "## üéì Master‚Äôs Program in Data Science & Advanced Analytics \n",
    "**Nova IMS** | May 2025   \n",
    "**Course:** Business Cases with Data Science\n",
    "\n",
    "## üë• Team **Group A**  \n",
    "- **Alice Viegas** | 20240572  \n",
    "- **Bernardo Faria** | 20240579  \n",
    "- **Dinis Pinto** | 20240612  \n",
    "- **Daan van Holten** | 20240681\n",
    "- **Philippe Dutranoit** | 20240518"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa60489a",
   "metadata": {},
   "source": [
    "## üìä Project Overview  \n",
    "This notebook demonstrates a prototype chatbot powered by the Azure OpenAI Assistant, designed to support Fidelidade's sales agents. <br>\n",
    "This solution is platform-agnostic, meaning it can be integrated into any system or interface that best suits Fidelidade's needs.\n",
    "\n",
    "References:\n",
    "- https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eb3543",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3032e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages loading\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from openai import AzureOpenAI\n",
    "from PIL import Image\n",
    "from IPython.display import Markdown, display\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "31d9145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set API key and endpoint\n",
    "api_key = '8J6pTdfaGgA5r193UVLsBshUspqwNpal42Jse1aHaok1cWNTLpRkJQQJ99BDACYeBjFXJ3w3AAABACOGLa23'\n",
    "endpoint = 'https://ai-bcds.openai.azure.com/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b655d284",
   "metadata": {},
   "source": [
    "We have identified several websites that may be valuable sources of information for the chatbot to scrape in order to provide accurate and relevant responses, based on Fidelidade‚Äôs presentation. These sources are flexible and can be updated, replaced, or removed as needed. <br>\n",
    "Some of the websites are blocked. Getting the approvals from these public websites so their information can be used in the chatbot may enrich it even further with accurate and relevant information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b5d97777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "current_folder = os.getcwd()\n",
    "data_folder = current_folder\n",
    "data_folder_full_path = os.path.abspath(data_folder)\n",
    "url_list = [\n",
    "    # Banks\n",
    "    \"https://www.cgd.pt/Particulares/Poupanca-Investimento/Depositos-a-Prazo-e-Poupanca/Pages/Depositos-a-Prazo-e-Contas-Poupanca.aspx\",\n",
    "    \"https://www.santander.pt/poupancas\",\n",
    "    \"https://www.millenniumbcp.pt/poupanca/reforco-frequente\",\n",
    "    \"https://www.bancobpi.pt/particulares/poupar-investir/depositos-prazo\",\n",
    "\n",
    "    # Investment funds\n",
    "    # \"https://www.cgd.pt/Particulares/Poupanca-Investimento/Fundos-de-Investimento/Pages/Fundos-de-Investimento.aspx\",\n",
    "    \"https://www.casadeinvestimentos.pt/\",\n",
    "    \"https://optimize.pt/\",\n",
    "\n",
    "    # Savings Certificates\n",
    "    \"https://www.igcp.pt/pt/noticias/taxas-de-juro-dos-certificados-de-aforro-das-series-b-c-d-e-e-f-em-janeiro-de-2025\",\n",
    "\n",
    "    # Tax, Regulatory Guidelines, Financial Literacy\n",
    "    \"https://www.consumidor.asf.com.pt/poupan%C3%A7a/seguros-de-capitaliza%C3%A7%C3%A3o\",\n",
    "    # \"https://bpstat.bportugal.pt/conteudos/noticias/2463/\",\n",
    "    # \"https://www.cmvm.pt/\",\n",
    "    # \"https://www.todoscontam.pt/\"\n",
    "]\n",
    "agent_data = 'AgentFiles.pkl'     \n",
    "\n",
    "assistantFilename = 'AssistantID.TXT'\n",
    "assistant_id = None\n",
    "assistant = None\n",
    "\n",
    "displayedMessagesIDs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c11b0d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = endpoint,\n",
    "    api_key= api_key,\n",
    "    api_version=\"2024-05-01-preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a12d77e",
   "metadata": {},
   "source": [
    "## üß† Prompt Structure and Rationale\n",
    "\n",
    "### üéØ **Purpose of the Prompt**\n",
    "The prompt defines the behavior, tone, and limitations of a virtual assistant designed to support Fidelidade‚Äôs sales agents. Given the sensitive nature of financial information and the need for accuracy in customer service, the prompt is deliberately **descriptive** and **structured** to minimize ambiguity and ensure consistency. Some example responses are also provided as part of the prompt, so the tone and structure of the responses are very clear.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç **Prompt Structure Breakdown**\n",
    "\n",
    "1. **### Fun√ß√£o (Role)**  \n",
    "   This section outlines the **core responsibilities** and **communication style** expected from the assistant:\n",
    "   - Defines the assistant as a **specialist** in Fidelidade‚Äôs savings and insurance products.\n",
    "   - Emphasizes the importance of **clarity, accuracy, and professionalism**.\n",
    "   - Specifies expectations for **tone** (empathetic, accessible) and **style** (FAQ-like, user-friendly).\n",
    "   - Encourages the assistant to offer **helpful next steps** and cite **sources** to build trust and transparency.\n",
    "\n",
    "2. **### Restri√ß√µes (Constraints)**  \n",
    "   Clearly defines **boundaries** and **rules** the assistant must follow:\n",
    "   - **Language Handling**: Maintain consistency with the user‚Äôs language (e.g., Portuguese from Portugal vs. English).\n",
    "   - **Scope Control**: Gently redirects users who go off-topic, keeping the assistant focused and relevant.\n",
    "   - **Source Reliance**: Prohibits fabrication of information, reinforcing factual accuracy.\n",
    "   - **Ambiguity Handling**: Instructs the assistant to ask clarifying questions when needed.\n",
    "   - **Escalation Guidance**: Recommends next steps when the assistant can't fully address a user‚Äôs question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3eea5d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized Prompt\n",
    "aRole = \"\"\"### Fun√ß√£o\n",
    "- √âs um assistente virtual da Fidelidade, especializado em apoiar os agentes de vendas.\n",
    "\n",
    "- A tua principal fun√ß√£o √© fornecer informa√ß√µes claras, rigorosas e atualizadas sobre os produtos de poupan√ßa My Savings e PPR Evoluir, incluindo compara√ß√µes quando apropriado.\n",
    "\n",
    "- Deves tamb√©m responder a perguntas frequentes sobre literacia financeira, bem como esclarecer d√∫vidas sobre seguros e produtos financeiros da Fidelidade.\n",
    "\n",
    "- Mant√©m sempre um tom profissional, emp√°tico e acess√≠vel, com uma comunica√ß√£o natural e fluida, pr√≥pria de uma intera√ß√£o de apoio ao cliente ou agente.\n",
    "\n",
    "- As tuas respostas devem ser objetivas, diretas ao ponto, f√°ceis de compreender, sem linguagem excessivamente t√©cnica ou termos complexos n√£o explicados. Foca-te sempre nas informa√ß√µes essenciais, garantindo que a resposta √© √∫til e adequada ao contexto.\n",
    "\n",
    "- Nunca inventes informa√ß√£o: apoia-te exclusivamente nos conte√∫dos fornecidos.\n",
    "\n",
    "- Mostra sempre a fonte da informa√ß√£o usada, indicando o nome do documento ou, sempre que poss√≠vel, um link direto para que o utilizador possa explorar mais detalhes por conta pr√≥pria.\n",
    "\n",
    "- Quando adequado, sugere pr√≥ximos passos √∫teis, como consultar outras sec√ß√µes do documento, usar ferramentas da Fidelidade, ou contactar um agente de outra √°rea para apoio adicional.\n",
    "\n",
    "O estilo de resposta deve seguir o modelo dos documentos de FAQs oficiais da Fidelidade.\n",
    "Exemplo de estrutura:\n",
    "Pergunta: O que √© o Fidelidade Savings?\n",
    "Resposta: O Fidelidade Savings √© uma solu√ß√£o de Poupan√ßa/Investimento assente numa plataforma 100% digital e inovadora da Fidelidade. Permite-lhe definir Objetivos de Poupan√ßa ou Objetivos de Investimento de forma simples e flex√≠vel, com comiss√µes nulas ou reduzidas, conforme previsto na documenta√ß√£o contratual e pr√©-contratual.\n",
    "\n",
    "### Restri√ß√µes\n",
    "- Linguagem: Responde sempre na mesma l√≠ngua utilizada pelo utilizador. Se a pergunta for feita em portugu√™s, responde em portugu√™s de Portugal. Se for feita em ingl√™s, responde em ingl√™s. Nunca mistures idiomas na mesma resposta.\n",
    "\n",
    "- Manter o foco: Se o utilizador se desviar do tema, redireciona educadamente a conversa com um tom amig√°vel e compreensivo. Exemplo de resposta: \"Pe√ßo desculpa, mas s√≥ posso responder a perguntas sobre os produtos da Fidelidade e literacia financeira. Posso ajudar com alguma dessas quest√µes?\"\n",
    "\n",
    "- Limites de conhecimento: Baseia as tuas respostas exclusivamente na informa√ß√£o presente nos documentos fornecidos. Se a pergunta estiver fora desse √¢mbito, responde com cordialidade: \"Lamento, mas n√£o tenho informa√ß√£o sobre esse tema espec√≠fico. Posso ajudar com alguma quest√£o sobre produtos da Fidelidade ou literacia financeira?\"\n",
    "\n",
    "- Ambiguidade: Se a pergunta for amb√≠gua ou incompleta, pede gentilmente mais detalhe antes de responder.\n",
    "\n",
    "- Encaminhamento: Quando n√£o conseguires ajudar ou a pergunta exigir an√°lise personalizada, sugere contactar um agente Fidelidade ou visitar os canais oficiais.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91896095",
   "metadata": {},
   "source": [
    "## Support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "413517ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the assistant with code interpreter capability\n",
    "def create_assistant():\n",
    "    \"\"\"\n",
    "    Creates an OpenAI assistant with the code interpreter (GPT-4o-2) and file search tools enabled.\n",
    "    \n",
    "    The assistant is initialized with a name (\"Fidz\") and custom prompt defined in the variable `aRole`.\n",
    "    The assistant is configured to use the GPT-4o-2 model with specific parameters for temperature and top_p.\n",
    "    After creation, the assistant's unique ID is saved to a file specified by `assistantFilename` for future use.\n",
    "\n",
    "    Returns:\n",
    "        assistant (openai.Assistant): The created assistant object.\n",
    "    \"\"\"\n",
    "    assistant = client.beta.assistants.create(\n",
    "        name=\"Fidz\",\n",
    "        instructions=aRole,\n",
    "        model=\"gpt-4o-2\",\n",
    "        temperature=0.15,\n",
    "        top_p=0.35,\n",
    "        tools=[{\"type\": \"file_search\"}]\n",
    "    )\n",
    "    assistant_id = assistant.id\n",
    "    \n",
    "    # Save the ID to a file\n",
    "    with open(assistantFilename, \"w\") as file:\n",
    "        file.write(assistant_id)\n",
    "    \n",
    "    return assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c2d6e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a new thread for a conversation\n",
    "def create_thread():\n",
    "    \"\"\"\n",
    "    Creates a new conversation thread using the OpenAI API.\n",
    "\n",
    "    Initializes an empty list `displayedMessagesIDs` (intended for tracking message IDs shown to the user),\n",
    "    and returns the created thread object.\n",
    "\n",
    "    Returns:\n",
    "        thread (openai.Thread): The newly created conversation thread.\n",
    "    \"\"\"\n",
    "    thread = client.beta.threads.create()\n",
    "    displayedMessagesIDs = []\n",
    "    return thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3a4691d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if the assistant exists\n",
    "def check_assistant_exists(assistant_id):\n",
    "    \"\"\"\n",
    "    Checks whether an assistant with the given ID exists in the OpenAI system.\n",
    "\n",
    "    Args:\n",
    "        assistant_id (str): The ID of the assistant to check.\n",
    "\n",
    "    Returns:\n",
    "        (bool, object): \n",
    "            - True and the assistant object if found.\n",
    "            - False and None if not found or an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.beta.assistants.retrieve(assistant_id)       \n",
    "        return True if response else False, response\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while checking the assistant: {e}\", assistant_id)\n",
    "        return False, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7e608369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add a message to the thread\n",
    "def add_message_to_thread(thread_id, user_message):\n",
    "    \"\"\"\n",
    "    Adds a user's message to the specified conversation thread.\n",
    "\n",
    "    Args:\n",
    "        thread_id (str): The ID of the thread to which the message will be added.\n",
    "        user_message (str): The content of the message from the user.\n",
    "\n",
    "    Returns:\n",
    "        message (openai.ThreadMessage): The created message object.\n",
    "    \"\"\"\n",
    "    message = client.beta.threads.messages.create(\n",
    "        thread_id=thread_id,\n",
    "        role=\"user\",\n",
    "        content=user_message\n",
    "    )\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04e1c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# Define chunking logic  \n",
    "def chunk_text(text, chunk_size=400, chunk_overlap=80):  \n",
    "    \"\"\"\n",
    "    Splits the input text into overlapping chunks.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The input text to be divided.\n",
    "        chunk_size (int, optional): The maximum number of characters in each chunk. Default is 400.\n",
    "        chunk_overlap (int, optional): The number of overlapping characters between consecutive chunks. Default is 80.\n",
    "\n",
    "    Returns:\n",
    "        list of str: A list of text chunks, each of size up to `chunk_size`, with `chunk_overlap` characters \n",
    "        shared between neighboring chunks to preserve context.\n",
    "\n",
    "    Example:\n",
    "        For text of length 1000, chunk_size=400, and chunk_overlap=80, the output will contain:\n",
    "        - Chunk 1: characters 0‚Äì399\n",
    "        - Chunk 2: characters 320‚Äì719\n",
    "        - Chunk 3: characters 640‚Äì1039 (trimmed if necessary)\n",
    "\n",
    "    Useful for:\n",
    "        - Preparing long texts for NLP tasks like embedding, summarization, or search.\n",
    "    \"\"\"\n",
    "    chunks = []  \n",
    "    start = 0  \n",
    "    while start < len(text):  \n",
    "        end = min(start + chunk_size, len(text))  \n",
    "        chunk = text[start:end]  \n",
    "        chunks.append(chunk)  \n",
    "        start += chunk_size - chunk_overlap  \n",
    "    return chunks  \n",
    "  \n",
    "# Function to extract text from PDF or TXT files  \n",
    "def extract_text(file_path):  \n",
    "    \"\"\"\n",
    "    Extracts text content from a PDF or TXT file.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The path to the input file. Supported formats are .pdf and .txt.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted text content from the file. If the file format is unsupported, returns an empty string.\n",
    "\n",
    "    Logic:\n",
    "        - If the file ends with '.pdf':\n",
    "            Uses PyPDF2's PdfReader to extract and join text from all pages.\n",
    "        - If the file ends with '.txt':\n",
    "            Opens and reads the entire file content as plain text.\n",
    "        - For unsupported file types:\n",
    "            Returns an empty string.\n",
    "    \"\"\"\n",
    "    if file_path.endswith(\".pdf\"):  \n",
    "        reader = PdfReader(file_path)  \n",
    "        text = \"\\n\".join(page.extract_text() or \"\" for page in reader.pages)  \n",
    "        return text  \n",
    "    elif file_path.endswith(\".txt\"):  \n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:  \n",
    "            return f.read()  \n",
    "    else:  \n",
    "        return \"\"  # Add other file types if needed  \n",
    "  \n",
    "# Function to scrape website content  \n",
    "def scrape_website(url):  \n",
    "    \"\"\"\n",
    "    Extracts visible text from a webpage, removing scripts and styles.\n",
    "\n",
    "    Parameters:\n",
    "        url (str): The website URL to scrape.\n",
    "\n",
    "    Returns:\n",
    "        str: Cleaned text content from the page, or an empty string on error.\n",
    "    \"\"\"\n",
    "    try:  \n",
    "        response = requests.get(url)  \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')  \n",
    "        for tag in soup(['script', 'style']):  \n",
    "            tag.decompose()  \n",
    "        text = soup.get_text(separator=' ', strip=True)  \n",
    "        return text  \n",
    "    except Exception as e:  \n",
    "        print(f\"Error scraping {url}: {e}\")  \n",
    "        return \"\"  \n",
    "  \n",
    "# Function to process and chunk files  \n",
    "def process_files(file_paths, chunk_store):  \n",
    "    for file_path in file_paths:  \n",
    "        text = extract_text(file_path)  \n",
    "        if text.strip():  \n",
    "            chunks = chunk_text(text, chunk_size=400, chunk_overlap=80)  \n",
    "            for i, chunk in enumerate(chunks):  \n",
    "                chunk_store.append({  \n",
    "                    \"text\": chunk,  \n",
    "                    \"source_file\": file_path,  \n",
    "                    \"chunk_id\": i  \n",
    "                })  \n",
    "  \n",
    "# Function to scrape websites and add to chunk store  \n",
    "def process_websites(url_list, chunk_store): \n",
    "    \"\"\"\n",
    "    Extracts and chunks text from files, storing results in chunk_store.\n",
    "\n",
    "    Parameters:\n",
    "        file_paths (list): List of file paths to process (.pdf or .txt).\n",
    "        chunk_store (list): List to append chunk dictionaries to.\n",
    "\n",
    "    Each chunk includes:\n",
    "        - 'text': Chunked text content\n",
    "        - 'source_file': Originating file path\n",
    "        - 'chunk_id': Index of the chunk\n",
    "    \"\"\" \n",
    "    for url in url_list:  \n",
    "        text = scrape_website(url)  \n",
    "        if text.strip():  \n",
    "            chunks = chunk_text(text, chunk_size=400, chunk_overlap=80)  \n",
    "            for i, chunk in enumerate(chunks):  \n",
    "                chunk_store.append({  \n",
    "                    \"text\": chunk,  \n",
    "                    \"source_file\": url,  \n",
    "                    \"chunk_id\": i  \n",
    "                })  \n",
    "  \n",
    "# Final export to Azure-compatible JSON format  \n",
    "def save_chunk_store(chunk_store, output_file=\"azure_vector_chunks.json\"): \n",
    "    \"\"\"\n",
    "    Saves chunked data to a JSON file in Azure-compatible format.\n",
    "\n",
    "    Parameters:\n",
    "        chunk_store (list): List of chunk dictionaries to export.\n",
    "        output_file (str): Output filename (default: 'azure_vector_chunks.json').\n",
    "\n",
    "    Each output entry contains:\n",
    "        - 'text': The chunked text\n",
    "        - 'metadata': Includes 'source_file' and 'chunk_id'\n",
    "    \"\"\" \n",
    "    azure_chunks = []  \n",
    "    for c in chunk_store:  \n",
    "        azure_chunks.append({  \n",
    "            \"text\": c[\"text\"],  \n",
    "            \"metadata\": {  \n",
    "                \"source_file\": c[\"source_file\"],  \n",
    "                \"chunk_id\": c[\"chunk_id\"]  \n",
    "            }  \n",
    "        })  \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:  \n",
    "        json.dump(azure_chunks, f, ensure_ascii=False, indent=2)  \n",
    "    print(f\"Saved {len(azure_chunks)} chunks to {output_file}\")  \n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ca6c791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_upload_files(url_list=url_list):\n",
    "    \"\"\"\n",
    "    Loads PDF/TXT files and URLs, extracts and chunks content, saves it in Azure-compatible format,\n",
    "    and uploads it to a vector store.\n",
    "\n",
    "    Parameters:\n",
    "        url_list (list): List of URLs to scrape and include in the chunk store.\n",
    "\n",
    "    Returns:\n",
    "        vector_store (object): The created and populated vector store, or None on failure.\n",
    "    \"\"\"  \n",
    "    folder_path = \".\"  # Current working directory  \n",
    "    print(\"Scanning current folder for PDF and TXT files...\")  \n",
    "    file_paths = [  \n",
    "        os.path.join(folder_path, file)  \n",
    "        for file in os.listdir(folder_path)  \n",
    "        if file.lower().endswith(('.pdf', '.txt'))  # Add .txt files for extraction  \n",
    "    ]  \n",
    "    print(\"Files found:\", file_paths)  \n",
    "  \n",
    "    if not file_paths and not url_list:  \n",
    "        print(\"No files or URLs provided.\")  \n",
    "        return None  \n",
    "  \n",
    "    # Chunk store to hold extracted text chunks  \n",
    "    chunk_store = []  \n",
    "  \n",
    "    # Process files and add to chunk store  \n",
    "    if file_paths:  \n",
    "        print(\"Processing files for chunking...\")  \n",
    "        process_files(file_paths, chunk_store)  \n",
    "  \n",
    "    # Process URLs for web scraping and add to chunk store  \n",
    "    if url_list:  \n",
    "        print(\"Processing websites for chunking...\")  \n",
    "        print(\"URLs to process:\", url_list)\n",
    "        process_websites(url_list, chunk_store)  \n",
    "  \n",
    "    # Save chunk store to Azure-compatible JSON format  \n",
    "    save_chunk_store(chunk_store, output_file=\"azure_vector_chunks.json\")  \n",
    "  \n",
    "    # Upload chunks to vector store  \n",
    "    print(\"Uploading chunks to vector store...\")  \n",
    "    try:  \n",
    "        # Create a new vector store (API client must be set up already)  \n",
    "        vector_store = client.vector_stores.create(name=\"Documents and Websites\")  \n",
    "        print(\"Vector store created:\", vector_store)  \n",
    "  \n",
    "        # Upload chunks as files (assuming `chunk_store` is compatible with the API)  \n",
    "        file_batch = client.vector_stores.file_batches.upload_and_poll(  \n",
    "            vector_store_id=vector_store.id,  \n",
    "            files=[open(\"azure_vector_chunks.json\", \"rb\")]  \n",
    "        )  \n",
    "        print(\"Upload batch result:\", file_batch)  \n",
    "  \n",
    "        # Poll file statuses until done  \n",
    "        while True:  \n",
    "            files = list(client.vector_stores.files.list(vector_store_id=vector_store.id))  \n",
    "            statuses = [f.status for f in files]  \n",
    "            print(\"File statuses:\", statuses)  \n",
    "            if all(s in (\"completed\", \"failed\") for s in statuses) and len(files) == 1:  \n",
    "                break  \n",
    "            time.sleep(2)  \n",
    "  \n",
    "        for f in files:  \n",
    "            print(f\"File: {f.id}, Status: {f.status}\")  \n",
    "  \n",
    "    except Exception as e:  \n",
    "        print(f\"Unexpected error: {str(e)}\")  \n",
    "        return None  \n",
    "  \n",
    "    # Save vector store object for later use  \n",
    "    try:  \n",
    "        with open(\"AgentFiles.pkl\", \"wb\") as file:  \n",
    "            pickle.dump(vector_store, file)  \n",
    "        print(\"Vector store saved to AgentFiles.pkl\")  \n",
    "    except Exception as e:  \n",
    "        print(f\"Error saving vector store: {str(e)}\")  \n",
    "  \n",
    "    print(\"Vector store created and populated:\", vector_store)  \n",
    "    return vector_store  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ebace25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display messages not displayed yet\n",
    "\n",
    "def display_messages(thread, message):\n",
    "    \"\"\"\n",
    "    Displays new assistant messages from a conversation thread that have not been shown yet.\n",
    "\n",
    "    This function fetches messages after the given message ID in ascending order, checks if \n",
    "    they are from the assistant and not yet displayed, then processes and shows them accordingly:\n",
    "      - For text messages, it extracts content, handles file or URL annotations by downloading \n",
    "        files or scraping URLs, and displays text in Markdown.\n",
    "      - For image messages, it downloads and opens the image for viewing.\n",
    "      \n",
    "    Messages already displayed are tracked using the global `displayedMessagesIDs` list to avoid duplicates.\n",
    "\n",
    "    Args:\n",
    "        thread (openai.Thread): The conversation thread object.\n",
    "        message (openai.ThreadMessage): The last displayed message object in the thread.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    chunk_store = []\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id, order='asc', after=message.id)\n",
    "    if messages:\n",
    "        for message in messages:\n",
    "            if message.id not in displayedMessagesIDs:\n",
    "\n",
    "                # Check if the message is from the assistant and print it\n",
    "                if message.role == 'assistant':\n",
    "                    # Load JSON message into a Python object\n",
    "                    answer = json.loads(message.model_dump_json(indent=2))\n",
    "                    # Show answer\n",
    "                    try:\n",
    "                        messageType = message.content[0].type\n",
    "                        # Add message id  to the list as displayed\n",
    "                        displayedMessagesIDs.append(message.id)\n",
    "\n",
    "                        # Text message\n",
    "                        if messageType == 'text':\n",
    "                            content = 'Assistant: ' + answer['content'][0]['text']['value']\n",
    "\n",
    "                            # Check for file or URL annotations\n",
    "                            file_link = None\n",
    "                            if 'annotations' in answer['content'][0]['text']:\n",
    "                                for annotation in answer['content'][0]['text']['annotations']:\n",
    "                                    if annotation['type'] == 'file_path':\n",
    "                                        file_link = annotation['text']\n",
    "                                        file_id = annotation['file_path'].get('file_id')\n",
    "                                        start_index = annotation.get('start_index')\n",
    "                                        end_index = annotation.get('end_index')\n",
    "                                        # Remove the link from the value if start_index and end_index are present\n",
    "                                        if start_index is not None and end_index is not None:\n",
    "                                            content = content[:start_index] + content[end_index:]\n",
    "                                        # Download the file and chunk\n",
    "                                        fileName = process_files(file_id, thread.id, message.id, file_link=file_link, is_image=False)\n",
    "\n",
    "                                    elif annotation['type'] == 'url':\n",
    "                                        url = annotation['text']\n",
    "                                        # Process the website and chunk\n",
    "                                        process_websites([url], thread_id=thread.id, message_id=message.id)\n",
    "\n",
    "                            # Display as Markdown\n",
    "                            display(Markdown(content))\n",
    "\n",
    "                        # Image\n",
    "                        elif messageType == 'image_file':\n",
    "                            # Get the ID of the image\n",
    "                            fileID = answer['content'][0]['image_file']['file_id']\n",
    "\n",
    "                            # Download the image\n",
    "                            fileName = process_files(fileID, thread.id, message.id, file_link='', is_image=True)\n",
    "\n",
    "                            # Display the image in the default image viewer\n",
    "                            image = Image.open(fileName)\n",
    "                            image.show()\n",
    "\n",
    "                    except:\n",
    "                        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2a700a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to send a message to the assistant and get a response\n",
    "def send_message_to_assistant(thread, user_input):\n",
    "    \"\"\"\n",
    "    Sends a user message to the assistant within a conversation thread, triggers the assistant's response,\n",
    "    and continuously monitors the assistant's run status until completion. During the process, it displays\n",
    "    any new messages from the assistant as they become available.\n",
    "\n",
    "    Args:\n",
    "        thread (openai.Thread): The conversation thread object where the message is sent.\n",
    "        user_input (str): The user's message content to send to the assistant.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Present feedback to user\n",
    "    print(\"You:\", user_input)\n",
    "    print(\"Thinking...\")\n",
    "    \n",
    "    # Add message to thread\n",
    "    message = add_message_to_thread(thread.id, user_input)\n",
    "\n",
    "    # Run the thread with the assistant\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id\n",
    "    )\n",
    "\n",
    "    # Loop until the run completes or fails\n",
    "    while run.status in ['queued', 'in_progress', 'cancelling']:\n",
    "        time.sleep(1)\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "        # Display any messages that are being become available\n",
    "        try:\n",
    "            display_messages(thread, message)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # Handle the response from the assistant\n",
    "    if run.status == 'completed':\n",
    "        # Display the messages\n",
    "        display_messages(thread, message)\n",
    "        \n",
    "    elif run.status == 'requires_action':\n",
    "        print(\"The assistant requires additional actions.\")\n",
    "    else:\n",
    "        print(f\"Run status: {run.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884a0dc4",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614e78a6",
   "metadata": {},
   "source": [
    "In this section the functions created above are used to create the chatbot and start the thread where the user can ask questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "014f7248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using assistant  asst_oVC7I85pF4er48LTB1eghU1i\n"
     ]
    }
   ],
   "source": [
    "# Check existent assistants\n",
    "if os.path.exists(assistantFilename):\n",
    "    with open(assistantFilename, \"r\") as file:\n",
    "        assistant_id = file.read()\n",
    "    \n",
    "    # Check on ChatGPT\n",
    "    exists, assistant = check_assistant_exists(assistant_id)\n",
    "    if exists:\n",
    "        # Get the vector_store\n",
    "        with open(agent_data, \"rb\") as file:  # Use binary mode to read\n",
    "            vector_store = pickle.load(file)\n",
    "        \n",
    "        assistant = client.beta.assistants.update(\n",
    "            assistant_id=assistant_id,\n",
    "            tool_resources={\n",
    "                            \"file_search\": {\n",
    "                            \"vector_store_ids\": [vector_store.id]\n",
    "                            }\n",
    "    }\n",
    ")\n",
    "        \n",
    "        # Provide feedback\n",
    "        print(\"Using assistant \", assistant_id)\n",
    "    else:\n",
    "        assistant_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b035898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create assistant if one does not exists - Load the data\n",
    "if assistant_id == None:\n",
    "    # Create assistant\n",
    "    print(\"Creating new assistant\")\n",
    "    assistant = create_assistant()\n",
    "    assistant_id = assistant.id\n",
    "    \n",
    "    # Load files from the local folder and upload to vector store\n",
    "    chunk_store= []\n",
    "    vector_store = load_and_upload_files()\n",
    "    print(\"Files uploaded.\")\n",
    "    \n",
    "    # Upload the assistant with the new files\n",
    "    assistant = client.beta.assistants.update(\n",
    "        assistant_id=assistant.id,\n",
    "        tool_resources = {\"file_search\": {\"vector_store_ids\": [vector_store.id]}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0af752c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New thread\n",
    "thread = create_thread()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d282d2b0",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c6050",
   "metadata": {},
   "source": [
    "Welcome! Type your message to chat with the assistant. <br>\n",
    "Type \"RESET\" to start a new chat or \"QUIT\" to exit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "589b552b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, I'm Fidz! Can I help you with anything related to Fidelidade's savings products, PPRs, or financial literacy? Type 'QUIT' to exit or 'RESET' to start a new chat.\n",
      "Exiting. Ciao!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hi, I'm Fidz! Can I help you with anything related to Fidelidade's savings products, PPRs, or financial literacy? Type 'QUIT' to exit or 'RESET' to start a new chat.\")\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "\n",
    "    if user_input.strip().upper() == \"QUIT\":\n",
    "        print(\"Exiting. Ciao!\")\n",
    "        break\n",
    "    elif user_input.strip().upper() == \"RESET\":\n",
    "        print(\"Starting a new chat...\")\n",
    "        thread = create_thread()\n",
    "    else:\n",
    "        send_message_to_assistant(thread, user_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
